I"Ü
<p><a class="text-link" href="http://workshops.inf.ed.ac.uk/accml/papers/2020-isca/2nd_AccML_paper_1.pdf">Link
to full paper</a></p>

<h2>The Problem</h2>

<p>Recently, artificial neural networks (ANNs) have emerged asthe  most  promising
candidates  for  performing  a  wide  range  oftasks such as image
classification and recognition, object detection,speech recognition, and
speech-to-text translation. There have beensignificant improvements in the
classification accuracies of ANNs,and  in  2015,  ANNs  achieved  human-level
accuracy at  theImageNet 2012 Visual Recognition Challenge. However,
thehigh classification performance of ANNs comes at the expenseof a large number
of memory accesses and compute operations,which results in higher power and
energy consumption. Recently,there has been an increased focus on developing
more efficient ANNs.</p>

<h2>What I did</h2>

<p>The main objective of this work is to accelerate the inference of TTFS-based SNNs on low-power devices, with minimal loss to accuracy. Therefore, this work focuses on (1) improving the classification performance of TTFS-based SNNs, and (2) designing a low-power neuromorphic hardware accelerator for performing inference of TTFS-based SNNs. The main contributions of this work can be listed as follows:</p>
<ul>
    <li> A new training algorithm that reduces the errors accumulated as a result of converting pre-trained neural network models to SNNs. 
    \item A novel low-power neuromorphic architecture, \nameofwork{} is designed to accelerate the inference operations of TTFS-based SNNs.
    \item An end-to-end neuromorphic technique that demonstrates the state-of-the-art performance and accuracy for TTFS-based SNNs.
&lt;/ul&gt;


<img class="center" src="/img/portfolio/DP_diagram.png" alt="" title="differential-privacy diagram" />
<div class="col three caption">
	Figure 1: Comparison between Global and Local Differential Privacy
</div>

<h2>Take Aways</h2>

In the past decade, Differential Privacy has become the de-facto framework for performing privacy analysis. There
are numerous relaxations of Differential Privacy with the most prominent ones
being epsilon,delta-Differential Privacy(DP) and R\'enyi Differential
Privacy(RDP).

<ul>
    <li>Healthcare datasets are usually plagued with missing values and class imbalance problems. It was found that these factors affected the utility privacy trade-off significantly.</li>
    <li> The most important factors were found to be the complexity of the dataset and the type of noise applied.</li>
</ul>

More details can be found in the paper 
<a class="text-link" href="https://www.dropbox.com/s/hwub4w4cfx7gc6l/A%20Comparative%20Study%20of%20Privacy-Preserving%20Techniques%20For%20Deep%20Learning.pdf?dl=0">here.</a>

</li></ul>
:ET