I"«<p><a class="text-link" href="https://www.dropbox.com/s/hwub4w4cfx7gc6l/A%20Comparative%20Study%20of%20Privacy-Preserving%20Techniques%20For%20Deep%20Learning.pdf?dl=0">Link
to full paper</a></p>

<h2>The Problem</h2>

<h2>What I did</h2>

<p>With growing concerns over privacy, this work aims to study privacy preservation
techniques using the differential privacy framework and, draw comparisons
between medical and non-medical datasets from a privacy standpoint. We compare
the use of Differentially Private Stochastic Gradient Descent(DP-SGD) and
Private Aggregation of Teacher Ensembles(PATE) on three publicly available
datasets.</p>

<p><img class="center" src="/img/portfolio/DP_diagram.png" alt="" title="differential-privacy diagram" /></p>
<div class="col three caption">
	Figure 1: Comparison between Global and Local Differential Privacy
</div>

<h2>Take Aways</h2>

<p>In the past decade, Differential Privacy has become the de-facto framework for performing privacy analysis. There
are numerous relaxations of Differential Privacy with the most prominent ones
being epsilon,delta-Differential Privacy(DP) and R'enyi Differential
Privacy(RDP).</p>

<ul>
    <li>Healthcare datasets are usually plagued with missing values and class imbalance problems. It was found that these factors affected the utility privacy trade-off significantly.</li>
    <li> The most important factors were found to be the complexity of the dataset and the type of noise applied.</li>
</ul>

<p>More details can be found in the paper 
<a class="text-link" href="https://www.dropbox.com/s/hwub4w4cfx7gc6l/A%20Comparative%20Study%20of%20Privacy-Preserving%20Techniques%20For%20Deep%20Learning.pdf?dl=0">here.</a></p>

:ET